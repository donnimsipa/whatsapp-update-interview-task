# Test Harness Overview

This directory wraps the shared tooling in `../scripts/` with a single entry point.

## Layout
- `run-all.sh` – Executes the full validation + performance matrix, logging every task (start/end/duration/status) to `outputs/reports/logs/`.
- `performance/extreme.sh` – Convenience shim for `scripts/performance/performance-extreme.sh` when you only want the extreme datasets.
- `README.md` – This file.

## What Each Task Does

- **Validation** – Runs the CLI against the official URS/UAT fixtures (`docs/interview/...`) and writes summary JSON to `outputs/validation/`. This is the baseline “happy path” scenario.
- **Invalid stress** – Generates a large dataset of invalid phone numbers and verifies the CLI only reports/updates the valid subset (skipped rows are logged).
- **Mixed stress** – Builds a large dataset with a configurable valid/invalid ratio (default 60% valid) to ensure partial success handling and logging behave correctly.
- **Nominal performance** – Benchmarks the CLI with small-to-medium uniform datasets (100/1K/5K) and captures wall-clock timings in `outputs/performance/go-time-*.log` or `node-time-*.log`.
- **Extreme performance** – Generates 50K/100K/500K/1M datasets (valid/invalid/mixed/uniform modes) and records timings plus summaries; can be skipped via `--skip-extreme` if you only need the lighter suite.

## Standard Workflow
```bash
bash test/run-all.sh                          # Full sweep (Go + Node)
bash test/run-all.sh --skip-extreme           # Same sweep, skip the extreme benchmark stage
bash scripts/reports/build-run-summary.sh      # Rebuild Markdown summary from latest JSON log
```

Running the harness produces two artefacts:

1. `outputs/reports/logs/run-<timestamp>.json` – machine-readable run log (task list, wall times, exit codes).
2. `outputs/reports/run-summary-<timestamp>.md` – human-readable digest regenerated by the report script.

## Latest Snapshot (run 20250925T074114Z)

| Task | Status | Start (UTC) | Finish (UTC) | Wall Time |
| --- | :---: | --- | --- | --- |
| Go validation | ✅ | 07:41:14 | 07:41:14 | 00:00:00 |
| Go invalid stress | ✅ | 07:41:14 | 07:41:15 | 00:00:01 |
| Go mixed stress | ✅ | 07:41:15 | 07:41:16 | 00:00:01 |
| Go nominal performance | ✅ | 07:41:16 | 07:41:18 | 00:00:02 |
| Go extreme performance | ✅ | 07:41:18 | 08:05:07 | 00:23:49 |
| Node validation | ✅ | 08:05:07 | 08:05:08 | 00:00:01 |
| Node invalid stress | ✅ | 08:05:08 | 08:05:09 | 00:00:01 |
| Node mixed stress | ✅ | 08:05:09 | 08:05:10 | 00:00:01 |
| Node nominal performance | ✅ | 08:05:10 | 08:05:12 | 00:00:02 |
| Node extreme performance | ✅ | 08:05:12 | 08:11:19 | 00:06:07 |

- **Total duration:** 00:30:05 (1,805 s)
- **Successes:** 10 / 10 (no skips, both runtimes available)
- Fixtures for the extreme sweep were generated via the Python dataset generator to avoid Node JSON limits.

## Pending / Skipped

None at the moment. The harness auto-detects missing runtimes and records skips; rerun after installing Go/Node if that happens.

## Regenerating Artefacts

To rebuild the Markdown from a specific run log:
```bash
bash scripts/reports/build-run-summary.sh --run-id 20250925T074114Z
```

Clean artefacts between runs with:
```bash
rm -rf outputs/validation/* outputs/performance/* outputs/reports/*
```
